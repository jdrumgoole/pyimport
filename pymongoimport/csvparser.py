

from datetime   import datetime
import csv
from enum import Enum
import logging

from pymongoimport.configfile import ConfigFile
from pymongoimport.type_converter import Converter


class ErrorResponse(Enum):
    Ignore = "ignore"
    Warn   = "warn"
    Fail   = "fail"

    def __str__(self):
        return self.value


class CSVParser:

    def __init__(self,
                 config_file : ConfigFile,
                 hasheader: bool = "False",
                 delimiter:str = ",",
                 onerror: ErrorResponse = ErrorResponse.Warn):

        self._logger = logging.getLogger(__name__)
        if delimiter == "tab":
            self._delimiter = "\t"
        else:
            self._delimiter = delimiter
        self._hasheader = hasheader
        self._onerror = onerror
        self._record_count = 0
        self._line_count = 0
        self._timestamp = None
        self._idField = None  # section on which name == _id
        self._log = logging.getLogger(__name__)
        self._converter = Converter(self._log)
        self._config = config_file

    # def add_timestamp(self, timestamp):
    #     '''
    #     timestamp = "now" generate time once for all docs
    #     timestamp = "gen" generate a new timestamp for each doc
    #     timestamp = "none" don't add timestamp field
    #     '''
    #     self._timestamp = timestamp
    #     if timestamp == "now":
    #         self._doc_template["timestamp"] = datetime.utcnow()
    #     return self._doc_template

    def hasheader(self):
        return self._hasheader

    def delimiter(self):
        return self._delimiter

    def get_dict_reader(self, f):
        if self._delimiter == "tab":
            self._delimiter = "\t"
        return csv.DictReader(f, fieldnames=self._config.fields(), delimiter=self._delimiter)

    def parse_line(self, dict_entry):
        """
        Make a new doc from a dictEntry generated by the csv.DictReader.

        :param dict_entry: the corresponding dictEntry for the column
        :return: the new doc

        WIP
        Do we make gen id generate a compound key or another field instead of ID
        """


        doc = {}

        self._record_count = self._record_count + 1

        if self._timestamp == "gen":
            doc['timestamp'] = datetime.utcnow()

        # print( "dictEntry: %s" % dictEntry )
        fieldCount = 0
        for k in self._config.fields():
            # print( "field: %s" % k )
            # print( "value: %s" % dictEntry[ k ])
            fieldCount = fieldCount + 1

            if dict_entry[k] is None:
                if self._hasheader:
                    self._line_count = self._record_count + 1
                else:
                    self._line_count = self._record_count

                msg = f"Value for field '{k}' at line {self._line_count} is 'None' which is not valid\n"
                # print(dictEntry)
                msg = msg + f"\t\t\tline:{self._record_count}:'{self._delimiter.join([str(v) for v in dict_entry.values()])}'"
                if self._onerror == ErrorResponse.Fail:
                    if self._log:
                        self._log.error(msg)
                    raise ValueError(msg)
                elif self._onerror == ErrorResponse.Warn:
                    if self._log:
                        self._log.warning(msg)
                    continue
                else:
                    continue

            if k.startswith("blank-") and self._onerror == ErrorResponse.Warn:  # ignore blank- columns
                if self._log:
                    self._log.info("Field %i is blank [blank-] : ignoring", fieldCount)
                continue

            # try:
            try:
                type_field = self._config.type_value(k)
                if type_field in ["date", "datetime"]:
                    format = self._config.format_value(k)
                    v = self._converter.convert_time(type_field, dict_entry[k], format)
                else:
                    v = self._converter.convert(type_field, dict_entry[k])

            except ValueError:

                if self._onerror == ErrorResponse.Fail:
                    if self._log:
                        self._log.error("Error at line %i at field '%s'", self._record_count, k)
                        self._log.error("type conversion error: Cannot convert '%s' to type %s", dict_entry[k],
                                        type_field)
                    raise
                elif self._onerror == ErrorResponse.Warn:
                    msg = "Parse failure at line {} at field '{}'".format(self._record_count, k)
                    msg = msg + " type conversion error: Cannot convert '{}' to type {} using string type instead".format(
                        dict_entry[k], type_field)
                    v = str(dict_entry[k])
                elif self._onerror == ErrorResponse.Ignore:
                    v = str(dict_entry[k])
                else:
                    raise ValueError("Invalid value for onerror: %s" % self._onerror)

            if self._config.hasNewName(k):
                assert (self._config.name_value(k) != None)
                doc[self._config.name_value(k)] = v
            else:
                doc[k] = v

        #             except ValueError :
        #                 self._log.error( "Value error parsing field : [%s]" , k )
        #                 self._log.error( "read value is: '%s'", dictEntry[ k ] )
        #                 self._log.error( "line: %i, '%s'", self._record_count, dictEntry )
        #                 #print( "ValueError parsing filed : %s with value : %s (type of field: $s) " % ( str(k), str(line[ k ]), str(fieldDict[ k]["type"])))
        #                 raise

        return doc

    def parse_csv_line(self, csv_line:list, add_locator:bool=False):
        """
        Make a new doc from a dictEntry generated by the csv.DictReader.

        :param dict_entry: the corresponding dictEntry for the column
        :return: the new doc

        WIP
        Do we make gen id generate a compound key or another field instead of ID
        """

        doc = {}

        if len(csv_line) == 1:
            self._logger.warning("Warning: only one field in "
                                 "input line. Do you have the "
                                 "right delimiter set ? "
                                 "( current delimiter is : '%s')",
                                 self._config.delimiter())
            self._logger.warning(f"input line : {csv_line}")

        self._record_count = self._record_count + 1

        if self._timestamp == "gen":
            doc['timestamp'] = datetime.utcnow()

        # print( "dictEntry: %s" % dictEntry )
        field_count = 0
        for i,k in enumerate(self._config.fields()):
            # print( "field: %s" % k )
            # print( "value: %s" % dictEntry[ k ])
            field_count = field_count + 1

            if csv_line[i] is None:
                if self._hasheader:
                    self._line_count = self._record_count + 1
                else:
                    self._line_count = self._record_count

                msg = f"Value for field '{k}' at line {self._line_count} is 'None' which is not valid\n"
                # print(dictEntry)
                msg = msg + f"\t\t\tline:{self._record_count}:'{self._delimiter.join([str(v) for v in csv_line])}'"
                if self._onerror == ErrorResponse.Fail:
                    if self._log:
                        self._log.error(msg)
                    raise ValueError(msg)
                elif self._onerror == ErrorResponse.Warn:
                    if self._log:
                        self._log.warning(msg)
                    continue
                else:
                    continue

            if k.startswith("blank-") and self._onerror == ErrorResponse.Warn:  # ignore blank- columns
                if self._log:
                    self._log.info("Field %i is blank [blank-] : ignoring", field_count)
                continue

            # try:
            try:
                type_field = self._config.type_value(k)
                if type_field in ["date", "datetime"]:
                    fmt = self._config.format_value(k)
                    v = self._converter.convert_time(type_field, csv_line[i], fmt)
                else:
                    v = self._converter.convert(type_field, csv_line[i])

            except ValueError:

                if self._onerror == ErrorResponse.Fail:
                    if self._log:
                        self._log.error("Error at line %i at field '%s'", self._record_count, k)
                        self._log.error("type conversion error: Cannot convert '%s' to type %s", csv_line[i],
                                        type_field)
                    raise
                elif self._onerror == ErrorResponse.Warn:
                    msg = "Parse failure at line {} at field '{}'".format(self._record_count, k)
                    msg = msg + " type conversion error: Cannot convert '{}' to type {} using string type instead".format(
                        csv_line[i], type_field)
                    v = str(csv_line[i])
                elif self._onerror == ErrorResponse.Ignore:
                    v = str(csv_line[i])
                else:
                    raise ValueError("Invalid value for onerror: %s" % self._onerror)

            if self._config.hasNewName(k):
                assert (self._config.name_value(k) is not None)
                doc[self._config.name_value(k)] = v
            else:
                doc[k] = v

        #             except ValueError :
        #                 self._log.error( "Value error parsing field : [%s]" , k )
        #                 self._log.error( "read value is: '%s'", dictEntry[ k ] )
        #                 self._log.error( "line: %i, '%s'", self._record_count, dictEntry )
        #                 #print( "ValueError parsing filed : %s with value : %s (type of field: $s) " % ( str(k), str(line[ k ]), str(fieldDict[ k]["type"])))
        #                 raise

        return doc


    def parse_file(self, filename:str, add_locator:bool=True, limit:int=0)->dict:

        with open(filename, newline="" ) as csv_file:

            reader = csv.reader(csv_file, delimiter=self._delimiter)

            for i, row in enumerate(reader):

                if limit > 0 :
                    if i >= limit :
                        break

                if self.hasheader() and i == 0:  # skip header line
                    continue

                doc = self.parse_csv_line(row)
                if add_locator:
                    doc['locator'] = {"f": filename, "n": i + 1}

                yield doc

